{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport scipy\nimport cv2\nimport os\nimport pickle\nimport librosa\nimport librosa.display\nfrom IPython.display import Audio\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom tensorflow import keras\nimport os.path\nfrom os import path\nimport shutil\nshutil.rmtree('/kaggle/working', ignore_errors=True)\nos.makedirs('/kaggle/working/spectrograms')\nos.makedirs('/kaggle/working/tempograms')\nos.makedirs('/kaggle/working/tonnetzgrams')\nos.makedirs('/kaggle/working/spectral_contrastgrams')\nos.makedirs('/kaggle/working/chromagrams')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T15:12:03.490144Z","iopub.execute_input":"2023-09-29T15:12:03.490410Z","iopub.status.idle":"2023-09-29T15:12:12.338056Z","shell.execute_reply.started":"2023-09-29T15:12:03.490384Z","shell.execute_reply":"2023-09-29T15:12:12.337342Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"**1.Spectrogram**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport librosa.display, os\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef create_spectrogram(audio_file, image_file):\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1)\n    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n\n    y, sr = librosa.load(audio_file)\n    ms = librosa.feature.melspectrogram(y, sr=sr)\n    log_ms = librosa.power_to_db(ms, ref=np.max)\n    librosa.display.specshow(log_ms, sr=sr)\n\n    fig.savefig(image_file)\n    plt.close(fig)\n    \ndef create_pngs_from_wavs(input_path, output_path):\n    if not os.path.exists(output_path):\n        os.makedirs(output_path)\n\n    dir = os.listdir(input_path)\n\n    for i, file in enumerate(dir):\n        input_file = os.path.join(input_path, file)\n        output_file = os.path.join(output_path, file.replace('.wav', '.png'))\n        create_spectrogram(input_file, output_file)\n\nfor files in os.listdir(\"/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original\"):\n    try:\n        str=os.path.join(\"/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original\", files)\n        create_pngs_from_wavs(str, '/kaggle/working/spectrograms/'+files)\n    except Exception as e:\n        print(\"Error loading file:\")\n        print(\"Error message:\")","metadata":{"execution":{"iopub.status.busy":"2023-09-29T14:32:07.668352Z","iopub.execute_input":"2023-09-29T14:32:07.668633Z","iopub.status.idle":"2023-09-29T14:36:11.542093Z","shell.execute_reply.started":"2023-09-29T14:32:07.668606Z","shell.execute_reply":"2023-09-29T14:36:11.541516Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n","output_type":"stream"},{"name":"stdout","text":"Error loading file:\nError message:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAd0AAAFDCAYAAAB/UdRdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPFUlEQVR4nO3cX6jkd3nH8c9jYirVqKVZQbKJSelaXbSgPYQUoaZoS5KLzYWtJCBWCS7YRkoVIcUSJV5ZqQUhrW6pWAWN0QtZcEsubCQgRrJiDSYhso3WbBSy/stN0Jj26cUZy3HdzZls5jzrnLxecGB+v/memYcvh/PemTP7q+4OALDznnW2BwCAZwrRBYAhogsAQ0QXAIaILgAMEV0AGLJtdKvqY1X1SFV98zT3V1V9uKqOVdU9VfXq1Y8JAOtvmVe6H09y5ZPcf1WSfYuvg0n++emPBQC7z7bR7e47k/zoSZZck+QTvemuJC+sqhevakAA2C1W8TfdC5M8tOX4+OIcALDFuZNPVlUHs/kWdJ773Of+wcte9rLJpweAp+1rX/vaD7p7z5l87yqi+3CSi7Yc712c+xXdfSjJoSTZ2Njoo0ePruDpAWBOVf33mX7vKt5ePpzkzYtPMV+e5NHu/v4KHhcAdpVtX+lW1aeTXJHkgqo6nuS9SZ6dJN39kSRHklyd5FiSx5K8daeGBYB1tm10u/u6be7vJH+1sokAYJdyRSoAGCK6ADBEdAFgiOgCwBDRBYAhogsAQ0QXAIaILgAMEV0AGCK6ADBEdAFgiOgCwBDRBYAhogsAQ0QXAIaILgAMEV0AGCK6ADBEdAFgiOgCwBDRBYAhogsAQ0QXAIaILgAMEV0AGCK6ADBEdAFgiOgCwBDRBYAhogsAQ0QXAIaILgAMEV0AGCK6ADBEdAFgiOgCwBDRBYAhogsAQ0QXAIaILgAMEV0AGCK6ADBEdAFgiOgCwBDRBYAhogsAQ0QXAIaILgAMEV0AGLJUdKvqyqp6oKqOVdWNp7j/4qq6o6q+XlX3VNXVqx8VANbbttGtqnOS3JLkqiT7k1xXVftPWvZ3SW7r7lcluTbJP616UABYd8u80r0sybHufrC7H09ya5JrTlrTSZ6/uP2CJN9b3YgAsDssE90Lkzy05fj44txW70vypqo6nuRIknec6oGq6mBVHa2qoydOnDiDcQFgfa3qg1TXJfl4d+9NcnWST1bVrzx2dx/q7o3u3tizZ8+KnhoA1sMy0X04yUVbjvcuzm11fZLbkqS7v5LkOUkuWMWAALBbLBPdu5Psq6pLq+q8bH5Q6vBJa76b5HVJUlUvz2Z0vX8MAFtsG93ufiLJDUluT3J/Nj+lfG9V3VxVBxbL3pXkbVX1jSSfTvKW7u6dGhoA1tG5yyzq7iPZ/IDU1nM3bbl9X5LXrHY0ANhdXJEKAIaILgAMEV0AGCK6ADBEdAFgiOgCwBDRBYAhogsAQ0QXAIaILgAMEV0AGCK6ADBEdAFgiOgCwBDRBYAhogsAQ0QXAIaILgAMEV0AGCK6ADBEdAFgiOgCwBDRBYAhogsAQ0QXAIaILgAMEV0AGCK6ADBEdAFgiOgCwBDRBYAhogsAQ0QXAIaILgAMEV0AGCK6ADBEdAFgiOgCwBDRBYAhogsAQ0QXAIaILgAMEV0AGCK6ADBEdAFgiOgCwBDRBYAhogsAQ5aKblVdWVUPVNWxqrrxNGveWFX3VdW9VfWp1Y4JAOvv3O0WVNU5SW5J8idJjie5u6oOd/d9W9bsS/K3SV7T3T+uqhft1MAAsK6WeaV7WZJj3f1gdz+e5NYk15y05m1JbunuHydJdz+y2jEBYP0tE90Lkzy05fj44txWL03y0qr6clXdVVVXrmpAANgttn17+Sk8zr4kVyTZm+TOqnpld/9k66KqOpjkYJJcfPHFK3pqAFgPy7zSfTjJRVuO9y7ObXU8yeHu/nl3fzvJt7IZ4V/S3Ye6e6O7N/bs2XOmMwPAWlomuncn2VdVl1bVeUmuTXL4pDWfz+ar3FTVBdl8u/nB1Y0JAOtv2+h29xNJbkhye5L7k9zW3fdW1c1VdWCx7PYkP6yq+5LckeTd3f3DnRoaANZRdfdZeeKNjY0+evToWXluADhTVfW17t44k+91RSoAGCK6ADBEdAFgiOgCwBDRBYAhogsAQ0QXAIaILgAMEV0AGCK6ADBEdAFgiOgCwBDRBYAhogsAQ0QXAIaILgAMEV0AGCK6ADBEdAFgiOgCwBDRBYAhogsAQ0QXAIaILgAMEV0AGCK6ADBEdAFgiOgCwBDRBYAhogsAQ0QXAIaILgAMEV0AGCK6ADBEdAFgiOgCwBDRBYAhogsAQ0QXAIaILgAMEV0AGCK6ADBEdAFgiOgCwBDRBYAhogsAQ0QXAIaILgAMEV0AGLJUdKvqyqp6oKqOVdWNT7LuDVXVVbWxuhEBYHfYNrpVdU6SW5JclWR/kuuqav8p1p2f5K+TfHXVQwLAbrDMK93Lkhzr7ge7+/Ektya55hTr3p/kA0l+usL5AGDXWCa6FyZ5aMvx8cW5/1dVr05yUXd/YYWzAcCu8rQ/SFVVz0ryoSTvWmLtwao6WlVHT5w48XSfGgDWyjLRfTjJRVuO9y7O/cL5SV6R5EtV9Z0klyc5fKoPU3X3oe7e6O6NPXv2nPnUALCGlonu3Un2VdWlVXVekmuTHP7Fnd39aHdf0N2XdPclSe5KcqC7j+7IxACwpraNbnc/keSGJLcnuT/Jbd19b1XdXFUHdnpAANgtzl1mUXcfSXLkpHM3nWbtFU9/LADYfVyRCgCGiC4ADBFdABgiugAwRHQBYIjoAsAQ0QWAIaILAENEFwCGiC4ADBFdABgiugAwRHQBYIjoAsAQ0QWAIaILAENEFwCGiC4ADBFdABgiugAwRHQBYIjoAsAQ0QWAIaILAENEFwCGiC4ADBFdABgiugAwRHQBYIjoAsAQ0QWAIaILAENEFwCGiC4ADBFdABgiugAwRHQBYIjoAsAQ0QWAIaILAENEFwCGiC4ADBFdABgiugAwRHQBYIjoAsAQ0QWAIaILAENEFwCGLBXdqrqyqh6oqmNVdeMp7n9nVd1XVfdU1Rer6iWrHxUA1tu20a2qc5LckuSqJPuTXFdV+09a9vUkG939+0k+l+TvVz0oAKy7ZV7pXpbkWHc/2N2PJ7k1yTVbF3T3Hd392OLwriR7VzsmAKy/ZaJ7YZKHthwfX5w7neuT/Pup7qiqg1V1tKqOnjhxYvkpAWAXWOkHqarqTUk2knzwVPd396Hu3ujujT179qzyqQHg1965S6x5OMlFW473Ls79kqp6fZL3JHltd/9sNeMBwO6xzCvdu5Psq6pLq+q8JNcmObx1QVW9KslHkxzo7kdWPyYArL9to9vdTyS5IcntSe5Pclt331tVN1fVgcWyDyZ5XpLPVtV/VtXh0zwcADxjLfP2crr7SJIjJ527acvt1694LgDYdVyRCgCGiC4ADBFdABgiugAwRHQBYIjoAsAQ0QWAIaILAENEFwCGiC4ADBFdABgiugAwRHQBYIjoAsAQ0QWAIaILAENEFwCGiC4ADBFdABgiugAwRHQBYIjoAsAQ0QWAIaILAENEFwCGiC4ADBFdABgiugAwRHQBYIjoAsAQ0QWAIaILAENEFwCGiC4ADBFdABgiugAwRHQBYIjoAsAQ0QWAIaILAENEFwCGiC4ADBFdABgiugAwRHQBYIjoAsAQ0QWAIaILAEOWim5VXVlVD1TVsaq68RT3/0ZVfWZx/1er6pKVTwoAa27b6FbVOUluSXJVkv1Jrquq/Sctuz7Jj7v7d5P8Y5IPrHpQAFh3y7zSvSzJse5+sLsfT3JrkmtOWnNNkn9b3P5cktdVVa1uTABYf8tE98IkD205Pr44d8o13f1EkkeT/PYqBgSA3eLcySerqoNJDi4Of1ZV35x8/meIC5L84GwPsUvZ251hX3eOvd0Zv3em37hMdB9OctGW472Lc6dac7yqzk3ygiQ/PPmBuvtQkkNJUlVHu3vjTIbm9OzrzrG3O8O+7hx7uzOq6uiZfu8yby/fnWRfVV1aVecluTbJ4ZPWHE7yF4vbf5bkP7q7z3QoANiNtn2l291PVNUNSW5Pck6Sj3X3vVV1c5Kj3X04yb8m+WRVHUvyo2yGGQDYYqm/6Xb3kSRHTjp305bbP03y50/xuQ89xfUsx77uHHu7M+zrzrG3O+OM97W8CwwAM1wGEgCG7Hh0XUJyZyyxr++sqvuq6p6q+mJVveRszLmOttvbLeveUFVdVT4duoRl9rWq3rj4ub23qj41PeM6WuJ3wcVVdUdVfX3x++DqszHnuqmqj1XVI6f7r6216cOLfb+nql691AN39459ZfODV/+V5HeSnJfkG0n2n7TmL5N8ZHH72iSf2cmZdsPXkvv6x0l+c3H77fZ1dXu7WHd+kjuT3JVk42zP/ev+teTP7L4kX0/yW4vjF53tuX/dv5bc10NJ3r64vT/Jd8723OvwleSPkrw6yTdPc//VSf49SSW5PMlXl3ncnX6l6xKSO2Pbfe3uO7r7scXhXdn8/9Vsb5mf2SR5fzavMf7TyeHW2DL7+rYkt3T3j5Okux8ZnnEdLbOvneT5i9svSPK9wfnWVnffmc3/jXM61yT5RG+6K8kLq+rF2z3uTkfXJSR3xjL7utX12fwXGdvbdm8XbyNd1N1fmBxszS3zM/vSJC+tqi9X1V1VdeXYdOtrmX19X5I3VdXxbP4vlHfMjLbrPdXfw0mGLwPJvKp6U5KNJK8927PsBlX1rCQfSvKWszzKbnRuNt9iviKb78zcWVWv7O6fnM2hdoHrkny8u/+hqv4wm9dUeEV3/+/ZHuyZaKdf6T6VS0jmyS4hyS9ZZl9TVa9P8p4kB7r7Z0Ozrbvt9vb8JK9I8qWq+k42/5Zz2IeptrXMz+zxJIe7++fd/e0k38pmhDm9Zfb1+iS3JUl3fyXJc7J5TWaenqV+D59sp6PrEpI7Y9t9rapXJfloNoPrb2PLe9K97e5Hu/uC7r6kuy/J5t/LD3T3GV+L9Rlimd8Fn8/mq9xU1QXZfLv5wcEZ19Ey+/rdJK9Lkqp6eTaje2J0yt3pcJI3Lz7FfHmSR7v7+9t9046+vdwuIbkjltzXDyZ5XpLPLj6X9t3uPnDWhl4TS+4tT9GS+3p7kj+tqvuS/E+Sd3e3d72exJL7+q4k/1JVf5PND1W9xQub7VXVp7P5j8ALFn8Pf2+SZydJd38km38fvzrJsSSPJXnrUo9r7wFghitSAcAQ0QWAIaILAENEFwCGiC4ADBFdABgiugAwRHQBYMj/AZjNiq1BTsFgAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nfrom tensorflow.keras.utils import to_categorical\ndef load_images_from_path(path, label):\n    images = []\n    labels = []\n\n    for file in os.listdir(path):\n        try:\n            images.append(image.img_to_array(image.load_img(os.path.join(path, file), target_size=(224, 224, 3))))\n            if(label==\"blues\"):\n                labels.append(0)\n            elif(label==\"classical\"):\n                labels.append(1)\n            elif(label==\"country\"):\n                labels.append(2)\n            elif(label==\"disco\"):\n                labels.append(3)\n            elif(label==\"hiphop\"):\n                labels.append(4)\n            elif(label==\"jazz\"):\n                labels.append(5)\n            elif(label==\"metal\"):\n                labels.append(6)\n            elif(label==\"pop\"):\n                labels.append(7)\n            elif(label==\"reggae\"):\n                labels.append(8)\n            elif(label==\"rock\"):\n                labels.append(9)\n        except Exception as e:\n            print(\"Error loading file:\")\n            print(\"Error message:\")\n    return images, labels\ni=0\nx=[]\ny=[]\nfor genre in os.listdir(\"/kaggle/working/spectrograms\"):\n    print(genre)\n    genre_path = os.path.join(\"/kaggle/working/spectrograms\", genre)\n    file_count = 0\n    images=[]\n    labels=[]\n    images, labels = load_images_from_path(genre_path, genre)\n    #show_images(images)\n    x += images\n    y += labels\n    i=i+1\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.3, random_state=0)\n\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\n\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\nx_train_norm = preprocess_input(np.array(x_train))\nx_test_norm = preprocess_input(np.array(x_test))\ny_train_encoded = to_categorical(y_train)\ny_test_encoded = to_categorical(y_test)\ntrain_features = base_model.predict(x_train_norm)\ntest_features = base_model.predict(x_test_norm)\nmodel = Sequential()\nmodel.add(Flatten(input_shape=train_features.shape[1:]))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T14:55:30.643494Z","iopub.execute_input":"2023-09-29T14:55:30.644051Z","iopub.status.idle":"2023-09-29T14:56:00.406170Z","shell.execute_reply.started":"2023-09-29T14:55:30.644009Z","shell.execute_reply":"2023-09-29T14:56:00.405246Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"classical\nmetal\nrock\nhiphop\ncountry\njazz\nreggae\ndisco\npop\nblues\n","output_type":"stream"}]},{"cell_type":"code","source":"hist = model.fit(train_features, y_train_encoded, validation_data=(test_features, y_test_encoded), batch_size=10, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T14:56:09.319194Z","iopub.execute_input":"2023-09-29T14:56:09.319630Z","iopub.status.idle":"2023-09-29T14:58:30.274571Z","shell.execute_reply.started":"2023-09-29T14:56:09.319595Z","shell.execute_reply":"2023-09-29T14:58:30.273953Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Epoch 1/10\n65/65 [==============================] - 15s 217ms/step - loss: 40.4767 - accuracy: 0.3076 - val_loss: 4.7261 - val_accuracy: 0.5432\nEpoch 2/10\n65/65 [==============================] - 14s 218ms/step - loss: 1.4486 - accuracy: 0.7634 - val_loss: 4.3729 - val_accuracy: 0.6151\nEpoch 3/10\n65/65 [==============================] - 14s 213ms/step - loss: 1.3872 - accuracy: 0.8214 - val_loss: 2.5007 - val_accuracy: 0.6835\nEpoch 4/10\n65/65 [==============================] - 14s 218ms/step - loss: 0.3454 - accuracy: 0.9258 - val_loss: 2.4853 - val_accuracy: 0.6763\nEpoch 5/10\n65/65 [==============================] - 14s 213ms/step - loss: 0.1730 - accuracy: 0.9503 - val_loss: 2.9912 - val_accuracy: 0.6835\nEpoch 6/10\n65/65 [==============================] - 14s 218ms/step - loss: 0.1046 - accuracy: 0.9775 - val_loss: 2.7288 - val_accuracy: 0.7086\nEpoch 7/10\n65/65 [==============================] - 14s 213ms/step - loss: 0.2006 - accuracy: 0.9477 - val_loss: 3.4177 - val_accuracy: 0.6547\nEpoch 8/10\n65/65 [==============================] - 14s 220ms/step - loss: 0.1602 - accuracy: 0.9590 - val_loss: 3.6054 - val_accuracy: 0.6439\nEpoch 9/10\n65/65 [==============================] - 14s 215ms/step - loss: 0.3997 - accuracy: 0.9335 - val_loss: 4.2302 - val_accuracy: 0.5971\nEpoch 10/10\n65/65 [==============================] - 14s 214ms/step - loss: 0.3798 - accuracy: 0.9212 - val_loss: 4.2519 - val_accuracy: 0.5935\n","output_type":"stream"}]},{"cell_type":"code","source":"create_spectrogram('/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/classical/classical.00000.wav', '/kaggle/working/soso1.png')\nclass_labels = ['blues', 'classical', 'country', 'disco','hiphop','jazz','metal','pop','reggae','rock']\n\nx = image.load_img('/kaggle/working/soso1.png', target_size=(224, 224))\nx = image.img_to_array(x)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\ny = base_model.predict(x)\npredictions = model.predict(y)\n\nfor i, label in enumerate(class_labels):\n    print(f'{label}: {predictions[0][i]}')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T15:00:56.006755Z","iopub.execute_input":"2023-09-29T15:00:56.007105Z","iopub.status.idle":"2023-09-29T15:00:56.433089Z","shell.execute_reply.started":"2023-09-29T15:00:56.007069Z","shell.execute_reply":"2023-09-29T15:00:56.432324Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"blues: 1.1867142468355296e-12\nclassical: 0.9978988170623779\ncountry: 6.298153597569059e-18\ndisco: 0.0021012083161622286\nhiphop: 3.451485787713676e-14\njazz: 7.917481947838922e-11\nmetal: 2.741552916374825e-22\npop: 5.780676230595938e-19\nreggae: 7.502290664547279e-21\nrock: 1.8780121902040037e-10\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**2.Tempogram**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport librosa.display, os\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef create_tempogram(audio_file, image_file):\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1)\n    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n\n    y, sr = librosa.load(audio_file)\n    ms = librosa.feature.tempogram(y, sr=sr)\n    librosa.display.specshow(ms, sr=sr)\n\n    fig.savefig(image_file)\n    plt.close(fig)\n    \ndef create_pngs_from_wavs(input_path, output_path):\n    if not os.path.exists(output_path):\n        os.makedirs(output_path)\n\n    dir = os.listdir(input_path)\n\n    for i, file in enumerate(dir):\n        input_file = os.path.join(input_path, file)\n        output_file = os.path.join(output_path, file.replace('.wav', '.png'))\n        create_tempogram(input_file, output_file)\n\nfor files in os.listdir(\"/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original\"):\n    try:\n        str=os.path.join(\"/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original\", files)\n        create_pngs_from_wavs(str, '/kaggle/working/tempograms/'+files)\n    except Exception as e:\n        print(\"Error loading file:\")\n        print(\"Error message:\")\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nfrom tensorflow.keras.utils import to_categorical\ndef load_images_from_path(path, label):\n    images = []\n    labels = []\n\n    for file in os.listdir(path):\n        try:\n            images.append(image.img_to_array(image.load_img(os.path.join(path, file), target_size=(224, 224, 3))))\n            if(label==\"blues\"):\n                labels.append(0)\n            elif(label==\"classical\"):\n                labels.append(1)\n            elif(label==\"country\"):\n                labels.append(2)\n            elif(label==\"disco\"):\n                labels.append(3)\n            elif(label==\"hiphop\"):\n                labels.append(4)\n            elif(label==\"jazz\"):\n                labels.append(5)\n            elif(label==\"metal\"):\n                labels.append(6)\n            elif(label==\"pop\"):\n                labels.append(7)\n            elif(label==\"reggae\"):\n                labels.append(8)\n            elif(label==\"rock\"):\n                labels.append(9)\n        except Exception as e:\n            print(\"Error loading file:\")\n            print(\"Error message:\")\n    return images, labels\ni=0\nx=[]\ny=[]\nfor genre in os.listdir(\"/kaggle/working/tempograms\"):\n    genre_path = os.path.join(\"/kaggle/working/tempograms\", genre)\n    file_count = 0\n    images=[]\n    labels=[]\n    images, labels = load_images_from_path(genre_path, genre)\n    #show_images(images)\n    x += images\n    y += labels\n    i=i+1\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.3, random_state=0)\n\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\n\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\nx_train_norm = preprocess_input(np.array(x_train))\nx_test_norm = preprocess_input(np.array(x_test))\ny_train_encoded = to_categorical(y_train)\ny_test_encoded = to_categorical(y_test)\ntrain_features = base_model.predict(x_train_norm)\ntest_features = base_model.predict(x_test_norm)\nmodel = Sequential()\nmodel.add(Flatten(input_shape=train_features.shape[1:]))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nhist = model.fit(train_features, y_train_encoded, validation_data=(test_features, y_test_encoded), batch_size=10, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T15:12:20.461237Z","iopub.execute_input":"2023-09-29T15:12:20.461528Z","iopub.status.idle":"2023-09-29T15:24:55.977685Z","shell.execute_reply.started":"2023-09-29T15:12:20.461493Z","shell.execute_reply":"2023-09-29T15:24:55.976854Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n","output_type":"stream"},{"name":"stdout","text":"Error loading file:\nError message:\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n9412608/9406464 [==============================] - 0s 0us/step\nEpoch 1/10\n65/65 [==============================] - 18s 267ms/step - loss: 59.3266 - accuracy: 0.1650 - val_loss: 3.7705 - val_accuracy: 0.3094\nEpoch 2/10\n65/65 [==============================] - 16s 250ms/step - loss: 2.5721 - accuracy: 0.4256 - val_loss: 3.5958 - val_accuracy: 0.3058\nEpoch 3/10\n65/65 [==============================] - 16s 253ms/step - loss: 1.8188 - accuracy: 0.5398 - val_loss: 2.2637 - val_accuracy: 0.3993\nEpoch 4/10\n65/65 [==============================] - 16s 250ms/step - loss: 0.8347 - accuracy: 0.7005 - val_loss: 2.7766 - val_accuracy: 0.3561\nEpoch 5/10\n65/65 [==============================] - 17s 256ms/step - loss: 0.8941 - accuracy: 0.7121 - val_loss: 2.3944 - val_accuracy: 0.4065\nEpoch 6/10\n65/65 [==============================] - 17s 257ms/step - loss: 0.6512 - accuracy: 0.7601 - val_loss: 2.6483 - val_accuracy: 0.3453\nEpoch 7/10\n65/65 [==============================] - 17s 269ms/step - loss: 0.4301 - accuracy: 0.8590 - val_loss: 2.0483 - val_accuracy: 0.3993\nEpoch 8/10\n65/65 [==============================] - 17s 261ms/step - loss: 0.2612 - accuracy: 0.9292 - val_loss: 2.5352 - val_accuracy: 0.4496\nEpoch 9/10\n65/65 [==============================] - 17s 266ms/step - loss: 0.2750 - accuracy: 0.9118 - val_loss: 2.2507 - val_accuracy: 0.4532\nEpoch 10/10\n65/65 [==============================] - 17s 260ms/step - loss: 0.2634 - accuracy: 0.9276 - val_loss: 2.0165 - val_accuracy: 0.4640\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"create_tempogram('/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/classical/classical.00000.wav', '/kaggle/working/soso1.png')\nclass_labels = ['blues', 'classical', 'country', 'disco','hiphop','jazz','metal','pop','reggae','rock']\n\nx = image.load_img('/kaggle/working/soso1.png', target_size=(224, 224))\nx = image.img_to_array(x)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\ny = base_model.predict(x)\npredictions = model.predict(y)\n\nfor i, label in enumerate(class_labels):\n    print(f'{label}: {predictions[0][i]}')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T15:25:05.756118Z","iopub.execute_input":"2023-09-29T15:25:05.756435Z","iopub.status.idle":"2023-09-29T15:25:06.518100Z","shell.execute_reply.started":"2023-09-29T15:25:05.756406Z","shell.execute_reply":"2023-09-29T15:25:06.517197Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"blues: 0.0007549335132353008\nclassical: 0.9901818633079529\ncountry: 0.0003648994315881282\ndisco: 4.527767487161327e-06\nhiphop: 4.146677383687347e-05\njazz: 1.562741317684413e-06\nmetal: 0.00023341939959209412\npop: 0.0009509099763818085\nreggae: 1.4909044693922624e-05\nrock: 0.007451566401869059\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**3.Tonnetzgram**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport librosa.display, os\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef create_tonnetzgram(audio_file, image_file):\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1)\n    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n\n    y, sr = librosa.load(audio_file)\n    ms = librosa.feature.tonnetz(y, sr=sr)\n    librosa.display.specshow(ms, sr=sr)\n\n    fig.savefig(image_file)\n    plt.close(fig)\n    \ndef create_pngs_from_wavs(input_path, output_path):\n    if not os.path.exists(output_path):\n        os.makedirs(output_path)\n\n    dir = os.listdir(input_path)\n\n    for i, file in enumerate(dir):\n        input_file = os.path.join(input_path, file)\n        output_file = os.path.join(output_path, file.replace('.wav', '.png'))\n        create_tonnetzgram(input_file, output_file)\n\nfor files in os.listdir(\"/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original\"):\n    try:\n        str=os.path.join(\"/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original\", files)\n        create_pngs_from_wavs(str, '/kaggle/working/tonnetzgrams/'+files)\n    except Exception as e:\n        print(\"Error loading file:\")\n        print(\"Error message:\")\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nfrom tensorflow.keras.utils import to_categorical\ndef load_images_from_path(path, label):\n    images = []\n    labels = []\n\n    for file in os.listdir(path):\n        try:\n            images.append(image.img_to_array(image.load_img(os.path.join(path, file), target_size=(224, 224, 3))))\n            if(label==\"blues\"):\n                labels.append(0)\n            elif(label==\"classical\"):\n                labels.append(1)\n            elif(label==\"country\"):\n                labels.append(2)\n            elif(label==\"disco\"):\n                labels.append(3)\n            elif(label==\"hiphop\"):\n                labels.append(4)\n            elif(label==\"jazz\"):\n                labels.append(5)\n            elif(label==\"metal\"):\n                labels.append(6)\n            elif(label==\"pop\"):\n                labels.append(7)\n            elif(label==\"reggae\"):\n                labels.append(8)\n            elif(label==\"rock\"):\n                labels.append(9)\n        except Exception as e:\n            print(\"Error loading file:\")\n            print(\"Error message:\")\n    return images, labels\ni=0\nx=[]\ny=[]\nfor genre in os.listdir(\"/kaggle/working/tonnetzgrams\"):\n    genre_path = os.path.join(\"/kaggle/working/tonnetzgrams\", genre)\n    file_count = 0\n    images=[]\n    labels=[]\n    images, labels = load_images_from_path(genre_path, genre)\n    #show_images(images)\n    x += images\n    y += labels\n    i=i+1\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.3, random_state=0)\n\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\n\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\nx_train_norm = preprocess_input(np.array(x_train))\nx_test_norm = preprocess_input(np.array(x_test))\ny_train_encoded = to_categorical(y_train)\ny_test_encoded = to_categorical(y_test)\ntrain_features = base_model.predict(x_train_norm)\ntest_features = base_model.predict(x_test_norm)\nmodel = Sequential()\nmodel.add(Flatten(input_shape=train_features.shape[1:]))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nhist = model.fit(train_features, y_train_encoded, validation_data=(test_features, y_test_encoded), batch_size=10, epochs=10)","metadata":{"execution":{"iopub.status.busy":"2023-09-29T15:43:25.603743Z","iopub.execute_input":"2023-09-29T15:43:25.604119Z","iopub.status.idle":"2023-09-29T15:57:52.782889Z","shell.execute_reply.started":"2023-09-29T15:43:25.604066Z","shell.execute_reply":"2023-09-29T15:57:52.782157Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/librosa/core/audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n","output_type":"stream"},{"name":"stdout","text":"Error loading file:\nError message:\nEpoch 1/10\n65/65 [==============================] - 17s 253ms/step - loss: 45.2285 - accuracy: 0.1624 - val_loss: 6.1271 - val_accuracy: 0.2842\nEpoch 2/10\n65/65 [==============================] - 16s 245ms/step - loss: 2.8903 - accuracy: 0.4474 - val_loss: 4.2145 - val_accuracy: 0.2626\nEpoch 3/10\n65/65 [==============================] - 16s 249ms/step - loss: 1.1827 - accuracy: 0.6712 - val_loss: 3.2598 - val_accuracy: 0.2914\nEpoch 4/10\n65/65 [==============================] - 16s 245ms/step - loss: 0.5127 - accuracy: 0.8332 - val_loss: 3.7034 - val_accuracy: 0.2878\nEpoch 5/10\n65/65 [==============================] - 16s 250ms/step - loss: 0.5639 - accuracy: 0.8442 - val_loss: 2.9436 - val_accuracy: 0.3957\nEpoch 6/10\n65/65 [==============================] - 16s 245ms/step - loss: 0.1444 - accuracy: 0.9519 - val_loss: 2.6753 - val_accuracy: 0.3741\nEpoch 7/10\n65/65 [==============================] - 16s 249ms/step - loss: 0.0738 - accuracy: 0.9791 - val_loss: 2.9588 - val_accuracy: 0.3705\nEpoch 8/10\n65/65 [==============================] - 16s 245ms/step - loss: 0.0749 - accuracy: 0.9836 - val_loss: 3.1459 - val_accuracy: 0.3561\nEpoch 9/10\n65/65 [==============================] - 16s 249ms/step - loss: 0.0446 - accuracy: 0.9902 - val_loss: 3.0839 - val_accuracy: 0.3813\nEpoch 10/10\n65/65 [==============================] - 16s 245ms/step - loss: 0.0689 - accuracy: 0.9799 - val_loss: 3.1330 - val_accuracy: 0.3921\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"create_tonnetzgram('/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/classical/classical.00000.wav', '/kaggle/working/soso1.png')\nclass_labels = ['blues', 'classical', 'country', 'disco','hiphop','jazz','metal','pop','reggae','rock']\n\nx = image.load_img('/kaggle/working/soso1.png', target_size=(224, 224))\nx = image.img_to_array(x)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\ny = base_model.predict(x)\npredictions = model.predict(y)\n\nfor i, label in enumerate(class_labels):\n    print(f'{label}: {predictions[0][i]}')","metadata":{"execution":{"iopub.status.busy":"2023-09-29T15:59:49.552366Z","iopub.execute_input":"2023-09-29T15:59:49.552926Z","iopub.status.idle":"2023-09-29T15:59:50.454711Z","shell.execute_reply.started":"2023-09-29T15:59:49.552872Z","shell.execute_reply":"2023-09-29T15:59:50.453935Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"blues: 1.06711596004061e-07\nclassical: 0.999194324016571\ncountry: 0.0006798551767133176\ndisco: 1.4043599549040664e-05\nhiphop: 1.9845333709689328e-11\njazz: 2.664150429154688e-07\nmetal: 5.041590611654101e-07\npop: 3.690625089802779e-05\nreggae: 1.707584971200049e-07\nrock: 7.37819864298217e-05\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**4.Chromagram**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport librosa.display, os\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef create_chromagram(audio_file, image_file):\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1)\n    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n\n    y, sr = librosa.load(audio_file)\n    ms = librosa.feature.chroma_stft(y, sr=sr)\n    librosa.display.specshow(ms, sr=sr)\n\n    fig.savefig(image_file)\n    plt.close(fig)\n    \ndef create_pngs_from_wavs(input_path, output_path):\n    if not os.path.exists(output_path):\n        os.makedirs(output_path)\n\n    dir = os.listdir(input_path)\n\n    for i, file in enumerate(dir):\n        input_file = os.path.join(input_path, file)\n        output_file = os.path.join(output_path, file.replace('.wav', '.png'))\n        create_chromagram(input_file, output_file)\n\nfor files in os.listdir(\"/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original\"):\n    try:\n        str=os.path.join(\"/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original\", files)\n        create_pngs_from_wavs(str, '/kaggle/working/chromagrams/'+files)\n    except Exception as e:\n        print(\"Error loading file:\")\n        print(\"Error message:\")\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nfrom tensorflow.keras.utils import to_categorical\ndef load_images_from_path(path, label):\n    images = []\n    labels = []\n\n    for file in os.listdir(path):\n        try:\n            images.append(image.img_to_array(image.load_img(os.path.join(path, file), target_size=(224, 224, 3))))\n            if(label==\"blues\"):\n                labels.append(0)\n            elif(label==\"classical\"):\n                labels.append(1)\n            elif(label==\"country\"):\n                labels.append(2)\n            elif(label==\"disco\"):\n                labels.append(3)\n            elif(label==\"hiphop\"):\n                labels.append(4)\n            elif(label==\"jazz\"):\n                labels.append(5)\n            elif(label==\"metal\"):\n                labels.append(6)\n            elif(label==\"pop\"):\n                labels.append(7)\n            elif(label==\"reggae\"):\n                labels.append(8)\n            elif(label==\"rock\"):\n                labels.append(9)\n        except Exception as e:\n            print(\"Error loading file:\")\n            print(\"Error message:\")\n    return images, labels\ni=0\nx=[]\ny=[]\nfor genre in os.listdir(\"/kaggle/working/chromagrams\"):\n    genre_path = os.path.join(\"/kaggle/working/chromagrams\", genre)\n    file_count = 0\n    images=[]\n    labels=[]\n    images, labels = load_images_from_path(genre_path, genre)\n    #show_images(images)\n    x += images\n    y += labels\n    i=i+1\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.3, random_state=0)\n\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\n\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\nx_train_norm = preprocess_input(np.array(x_train))\nx_test_norm = preprocess_input(np.array(x_test))\ny_train_encoded = to_categorical(y_train)\ny_test_encoded = to_categorical(y_test)\ntrain_features = base_model.predict(x_train_norm)\ntest_features = base_model.predict(x_test_norm)\nmodel = Sequential()\nmodel.add(Flatten(input_shape=train_features.shape[1:]))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nhist = model.fit(train_features, y_train_encoded, validation_data=(test_features, y_test_encoded), batch_size=10, epochs=10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_chromagram('/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/classical/classical.00000.wav', '/kaggle/working/soso1.png')\nclass_labels = ['blues', 'classical', 'country', 'disco','hiphop','jazz','metal','pop','reggae','rock']\n\nx = image.load_img('/kaggle/working/soso1.png', target_size=(224, 224))\nx = image.img_to_array(x)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\ny = base_model.predict(x)\npredictions = model.predict(y)\n\nfor i, label in enumerate(class_labels):\n    print(f'{label}: {predictions[0][i]}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5.Spectral_contrast**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport librosa.display, os\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef create_spectral(audio_file, image_file):\n    fig = plt.figure()\n    ax = fig.add_subplot(1, 1, 1)\n    fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n\n    y, sr = librosa.load(audio_file)\n    ms = librosa.feature.spectral_contrast(y, sr=sr)\n    librosa.display.specshow(ms, sr=sr)\n\n    fig.savefig(image_file)\n    plt.close(fig)\n    \ndef create_pngs_from_wavs(input_path, output_path):\n    if not os.path.exists(output_path):\n        os.makedirs(output_path)\n\n    dir = os.listdir(input_path)\n\n    for i, file in enumerate(dir):\n        input_file = os.path.join(input_path, file)\n        output_file = os.path.join(output_path, file.replace('.wav', '.png'))\n        create_spectral(input_file, output_file)\n\nfor files in os.listdir(\"/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original\"):\n    try:\n        str=os.path.join(\"/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original\", files)\n        create_pngs_from_wavs(str, '/kaggle/working/spectral_contrastgrams/'+files)\n    except Exception as e:\n        print(\"Error loading file:\")\n        print(\"Error message:\")\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nfrom tensorflow.keras.utils import to_categorical\ndef load_images_from_path(path, label):\n    images = []\n    labels = []\n\n    for file in os.listdir(path):\n        try:\n            images.append(image.img_to_array(image.load_img(os.path.join(path, file), target_size=(224, 224, 3))))\n            if(label==\"blues\"):\n                labels.append(0)\n            elif(label==\"classical\"):\n                labels.append(1)\n            elif(label==\"country\"):\n                labels.append(2)\n            elif(label==\"disco\"):\n                labels.append(3)\n            elif(label==\"hiphop\"):\n                labels.append(4)\n            elif(label==\"jazz\"):\n                labels.append(5)\n            elif(label==\"metal\"):\n                labels.append(6)\n            elif(label==\"pop\"):\n                labels.append(7)\n            elif(label==\"reggae\"):\n                labels.append(8)\n            elif(label==\"rock\"):\n                labels.append(9)\n        except Exception as e:\n            print(\"Error loading file:\")\n            print(\"Error message:\")\n    return images, labels\ni=0\nx=[]\ny=[]\nfor genre in os.listdir(\"/kaggle/working/spectral_contrastgrams\"):\n    genre_path = os.path.join(\"/kaggle/working/spectral_contrastgrams\", genre)\n    file_count = 0\n    images=[]\n    labels=[]\n    images, labels = load_images_from_path(genre_path, genre)\n    #show_images(images)\n    x += images\n    y += labels\n    i=i+1\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size=0.3, random_state=0)\n\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications.mobilenet import preprocess_input\n\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\nx_train_norm = preprocess_input(np.array(x_train))\nx_test_norm = preprocess_input(np.array(x_test))\ny_train_encoded = to_categorical(y_train)\ny_test_encoded = to_categorical(y_test)\ntrain_features = base_model.predict(x_train_norm)\ntest_features = base_model.predict(x_test_norm)\nmodel = Sequential()\nmodel.add(Flatten(input_shape=train_features.shape[1:]))\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nhist = model.fit(train_features, y_train_encoded, validation_data=(test_features, y_test_encoded), batch_size=10, epochs=10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_spectral('/kaggle/input/gtzan-dataset-music-genre-classification/Data/genres_original/classical/classical.00000.wav', '/kaggle/working/soso1.png')\nclass_labels = ['blues', 'classical', 'country', 'disco','hiphop','jazz','metal','pop','reggae','rock']\n\nx = image.load_img('/kaggle/working/soso1.png', target_size=(224, 224))\nx = image.img_to_array(x)\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\n\ny = base_model.predict(x)\npredictions = model.predict(y)\n\nfor i, label in enumerate(class_labels):\n    print(f'{label}: {predictions[0][i]}')","metadata":{},"execution_count":null,"outputs":[]}]}